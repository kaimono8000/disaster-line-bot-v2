import os
import json
import numpy as np
import faiss
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class RagSearcher:
    def __init__(self, json_path="chunks.json"):
        self.index = None
        self.chunks = []
        self.embeddings = []
        self._build_index(json_path)

    def _embed(self, text):
        if not text or not text.strip():
            print("âš ï¸ ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
            return np.zeros(1536, dtype=np.float32)

        response = client.embeddings.create(
            model="text-embedding-ada-002",
            input=[text]
        )
        return np.array(response.data[0].embedding, dtype=np.float32)

    def _build_index(self, json_path):
        with open(json_path, "r", encoding="utf-8") as f:
            self.chunks = json.load(f)

        texts = [chunk["text"] for chunk in self.chunks]
        self.embeddings = [self._embed(text) for text in texts]

        dim = len(self.embeddings[0])
        self.index = faiss.IndexFlatL2(dim)
        self.index.add(np.array(self.embeddings))

    def search(self, query, top_k=3):
        query_vec = self._embed(query).reshape(1, -1)
        distances, indices = self.index.search(query_vec, top_k)
        return [self.chunks[i]["text"] for i in indices[0]]

    def search_with_routing(self, query, top_k=3):
        # ã€Œé…ç½®ã€é–¢é€£ã®è³ªå•ã‹ã©ã†ã‹åˆ¤å®š
        keywords = ["é…ç½®", "é…å±", "ã©ã“ã«è¡Œã", "å½¹å‰²", "è¡Œå‹•", "è¡Œå‹•å ´æ‰€", "æ‹…å½“", "éƒ¨ç½²"]
        if any(word in query for word in keywords):
            print("ğŸ” é…ç½®é–¢é€£ãƒ¯ãƒ¼ãƒ‰ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚äººå“¡é…ç½®è¡¨ã«çµã£ã¦æ¤œç´¢ã—ã¾ã™ã€‚")

            # äººå“¡é…ç½®ã£ã½ã„ãƒãƒ£ãƒ³ã‚¯ã‚’æŠœãå‡ºã™
            filtered_chunks = [
                chunk for chunk in self.chunks
                if any(kw in chunk["text"] for kw in ["äººå“¡é…ç½®", "å½¹å‰²åˆ†æ‹…", "è¡Œå‹•åˆ†æ‹…", "é…ç½®è¡¨", "æ‰€å±"])
            ]

            if not filtered_chunks:
                print("âš ï¸ é…ç½®ãƒãƒ£ãƒ³ã‚¯ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸã®ã§é€šå¸¸æ¤œç´¢ã—ã¾ã™ã€‚")
                return self.search(query, top_k=top_k)

            texts = [chunk["text"] for chunk in filtered_chunks]
            embeds = [self._embed(t) for t in texts]
            temp_index = faiss.IndexFlatL2(len(embeds[0]))
            temp_index.add(np.array(embeds))

            query_vec = self._embed(query).reshape(1, -1)
            D, I = temp_index.search(query_vec, top_k)

            return [texts[i] for i in I[0]]

        # é€šå¸¸æ¤œç´¢
        return self.search(query, top_k=top_k)
